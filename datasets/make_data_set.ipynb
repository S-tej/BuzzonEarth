{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "from descartes import PolygonPatch\n",
    "from shapely.geometry import Point, Polygon, MultiPolygon, LineString\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm\n",
    "import shapely.speedups\n",
    "from shapely import wkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "def load_city_data_by_name(city_name, target_crs=\"epsg:3005\"):\n",
    "    city = ox.geocode_to_gdf(city_name)\n",
    "    city = ox.project_gdf(city)\n",
    "    geometry = city['geometry'].iloc[0]\n",
    "    geometry_cut = ox.utils_geo._quadrat_cut_geometry(geometry, quadrat_width=500)\n",
    "    polylist = [poly for poly in geometry_cut.geoms]\n",
    "    polyframe = gpd.GeoDataFrame(geometry=polylist)\n",
    "    polyframe.crs = city.crs\n",
    "    city_data = ox.project_gdf(polyframe, to_latlong=True)\n",
    "    # city_data = city_data.to_crs(target_crs)  # Reproject to the target CRS\n",
    "    # city_data['geometry_center'] = city_data['geometry'].centroid\n",
    "    return city_data\n",
    "\n",
    "\n",
    "def add_contains_place_column(city_data, places_data, contains_col_name):\n",
    "    places_points = [Point(x) for x in places_data['geometry']]\n",
    "    city_data[contains_col_name] = False\n",
    "\n",
    "    for index, row in city_data.iterrows():\n",
    "        grid_polygon = row['geometry']\n",
    "        for place_point in places_points:\n",
    "            if grid_polygon.contains(place_point):\n",
    "                city_data.at[index, contains_col_name] = True\n",
    "                break  # Exit the inner loop after finding a match\n",
    "\n",
    "    return city_data\n",
    "\n",
    "\n",
    "def load_poi_data(path, target_crs=\"epsg:3005\"):\n",
    "    df = pd.read_csv(path)\n",
    "    poi_data = gpd.GeoDataFrame(\n",
    "        df.loc[:, [c for c in df.columns if c != \"geometry\"]],\n",
    "        geometry=gpd.GeoSeries.from_wkt(df[\"geometry\"]),\n",
    "        crs=\"epsg:3005\",  # Assuming the original CRS is EPSG:4326 (geographic CRS)\n",
    "    )\n",
    "    poi_data = poi_data.to_crs(target_crs)  # Reproject to the target CRS\n",
    "    poi_data['geometry_center'] = poi_data['geometry'].centroid\n",
    "    return poi_data\n",
    "\n",
    "def add_contains_place_column(city_data, poi_data, contains_col_name):\n",
    "    places_points = poi_data['geometry'].centroid\n",
    "    city_data[contains_col_name] = 0  # Initialize the column with zero counts\n",
    "\n",
    "    for index, row in city_data.iterrows():\n",
    "        grid_polygon = row['geometry']\n",
    "        count = 0  # Counter for the number of occurrences\n",
    "\n",
    "        for place_point in places_points:\n",
    "            if grid_polygon.contains(place_point):\n",
    "                count += 1\n",
    "\n",
    "        city_data.at[index, contains_col_name] = count\n",
    "\n",
    "    return city_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_downlaoded_data = \"C:/Users/Ramesh Babu/BuzzOnEarth/datasets/raw/collected_data\"\n",
    "cities = glob(f\"{path_to_downlaoded_data}/germany_data/*\")\n",
    "cities = [city.split(\"\\\\\")[-1] for city in cities]\n",
    "print(cities)\n",
    "\n",
    "for city in tqdm(cities):\n",
    "    print(city)\n",
    "    if city == \"Berlin\":\n",
    "        pass\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    city_name = city\n",
    "    city_data = load_city_data_by_name(city)\n",
    "    poi_data_list = list(glob(f\"{path_to_downlaoded_data}/germany_data/{city_name}/*.csv\"))\n",
    "\n",
    "    for poi_data_path in tqdm(poi_data_list):\n",
    "        poi_data = load_poi_data(poi_data_path)\n",
    "        # Add contains_place column with a custom name\n",
    "        containment_col_name = poi_data_path.split('/')[-1].split('.')[0].split('-')[-1]\n",
    "        city_data = add_contains_place_column(city_data, poi_data, containment_col_name)\n",
    "        # Print the updated city data\n",
    "        # print(containment_col_name, city_data[containment_col_name].value_counts())\n",
    "    city_data.to_csv(f\"/{path_to_downlaoded_data}/final_data_combo/{city_name}_data.csv\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_data_path = glob(\"{path_to_downlaoded_data}/final_data_combo/*.csv\")\n",
    "\n",
    "all_city_data = []\n",
    "\n",
    "for city_path in tqdm(city_data_path):\n",
    "    city_name = city_path.split('/')[-1].split('_')[0]\n",
    "    city_data = pd.read_csv(city_path)\n",
    "    city_data['city'] = city_name\n",
    "    all_city_data.append(city_data)\n",
    "\n",
    "all_city_data = pd.concat(all_city_data)\n",
    "all_city_data.to_csv(\"{path_to_downlaoded_data}/final_data_combo/all_city_data.csv\")\n",
    "\n",
    "all_city_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_data_path = glob(\"{path_to_downlaoded_data}/final_data_combo/*.csv\")\n",
    "\n",
    "all_city_data = []\n",
    "\n",
    "for city_path in tqdm(city_data_path):\n",
    "    city_name = city_path.split('/')[-1].split('_')[0]\n",
    "    city_data = pd.read_csv(city_path)\n",
    "    city_data['city'] = city_name\n",
    "    all_city_data.append(city_data)\n",
    "\n",
    "all_city_data = pd.concat(all_city_data)\n",
    "all_city_data.to_csv(\"{path_to_downlaoded_data}/final_data_combo/all_city_data.csv\")\n",
    "\n",
    "all_city_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_population_column(city_data, poi_data, contains_col_name):\n",
    "    places_points = poi_data['geometry'].centroid\n",
    "    city_data[contains_col_name] = None  # Initialize the column with None values\n",
    "\n",
    "    for city_index, city_row in city_data.iterrows():\n",
    "        grid_polygon = city_row['geometry']\n",
    "        value = None  # Placeholder for the value of poi\n",
    "\n",
    "        for poi_index, place_point in places_points.iteritems():\n",
    "            if grid_polygon.contains(place_point):\n",
    "                poi_value = poi_data.at[poi_index, 'population']\n",
    "                value = poi_value\n",
    "                break\n",
    "\n",
    "        city_data.at[city_index, contains_col_name] = value\n",
    "\n",
    "    return city_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_data_path = glob(\"{path_to_downlaoded_data}/final_data_combo/*.csv\")\n",
    "\n",
    "all_city_data = []\n",
    "\n",
    "for city_path in tqdm(city_data_path):\n",
    "    if \"all_city_data_with_pop\" in city_path:\n",
    "        continue\n",
    "    city_name = city_path.split('/')[-1].split('_')[0]\n",
    "    city_data = pd.read_csv(city_path)\n",
    "    city_data['city'] = city_name\n",
    "    city_data['geometry'] = city_data['geometry'].apply(wkt.loads)\n",
    "    city_data = gpd.GeoDataFrame(city_data, geometry='geometry', crs=\"epsg:3005\")\n",
    "\n",
    "    #load population data\n",
    "    #{path_to_downlaoded_data}/population_data/pop_data_v1\n",
    "    population_data_path = f\"{path_to_downlaoded_data}/population_data/{city_name}, Germany_pop.csv\"\n",
    "    population_data_path = load_poi_data(population_data_path)\n",
    "    city_data = add_population_column(city_data, population_data_path, 'population')\n",
    "    all_city_data.append(city_data)\n",
    "all_city_data = pd.concat(all_city_data)\n",
    "all_city_data.to_csv(\"{path_to_downlaoded_data}/final_data_combo/all_city_data_with_pop.csv\")\n",
    "\n",
    "all_city_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_city_data.sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "condaenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
